---
layout: single
title: "🔬 RAG 최신 연구 동향"
date: 2026-02-14 10:00:00 +0900
categories:
  - 연구논문
tags:
  - "AI연구"
  - "논문"
author_profile: false
read_time: true
---

## RAG란 무엇인가

RAG(Retrieval-Augmented Generation)는 LLM의 지식 한계(지식 컷오프, 환각)를 보완하기 위해 외부 지식베이스에서 관련 문서를 검색해 생성에 활용하는 기법이다. 2020년 Meta AI의 Lewis et al. 논문에서 제안됐으며, 기업 AI 구축의 핵심 아키텍처로 자리 잡았다.

## RAG 기본 파이프라인

① 문서를 청크(Chunk)로 분할 → ② 임베딩 모델로 벡터화해 벡터 DB(Pinecone, Weaviate, Chroma 등)에 저장 → ③ 사용자 질문을 임베딩해 유사 문서 검색 → ④ 검색된 문서를 컨텍스트로 LLM에 주입해 답변 생성. LangChain, LlamaIndex 등의 프레임워크로 빠르게 구현할 수 있다.

## 최신 RAG 연구 트렌드

**Advanced RAG:** 청크 최적화(Semantic Chunking), 하이브리드 검색(벡터+키워드), 재순위(Reranking) 등으로 검색 품질을 높인다. **Graph RAG:** 문서 간 관계를 그래프로 표현해 복합적인 다단계 추론을 지원한다. Microsoft GraphRAG가 대표적이다. **Agentic RAG:** 에이전트가 검색-평가-재검색의 루프를 자율적으로 수행한다. **Long Context vs RAG:** 100만+ 토큰 컨텍스트 모델의 등장으로 RAG의 필요성이 줄어든다는 논의도 있지만, 비용·정밀도 면에서 RAG는 여전히 유효하다.

## 산업 적용 사례

기업 내부 지식 검색(사내 위키 Q&A), 법률·의료 문서 분석, 고객 지원 챗봇, 금융 리서치 자동화 등에 RAG가 폭넓게 쓰인다. 2026년에는 멀티모달 RAG(이미지·테이블 검색)와 실시간 웹 검색 통합 RAG가 주류가 될 전망이다.
